# GUI Agent新突破：仅用136个样本，基于R1风格的强化微调

今天我们要给大家介绍一个令人惊艳的研究成果——vivo AI实验室与香港中文大学联合打造的**UI-R1**。这个研究团队仅用**136个**高质量样本，就训练出了一个在GUI（图形用户界面）智能体任务上表现超越大多数7B模型的3B小模型！想要快速了解精华内容，可直接前往文章结尾查看"懒人速览"。

# 总览

• **核心突破**：vivo与港中文团队的UI-R1只用136个样本，通过强化学习训练出了超越大多数7B模型的GUI智能体

• **关键数据**：比起基础模型，UI-R1提高了行为类型准确率15%和定位准确率10.3%；与使用76K数据训练的大模型性能相当

• **技术创新**：设计了专用奖励函数、精选高质量数据、采用GRPO算法训练

• **实际意义**：证明了"质量胜于数量"的数据观，为资源受限环境下的模型训练提供新思路

• **未来影响**：将加速更智能的人机交互界面发展，使AI真正能"看懂"并操作各种设备界面



## 01 背景：为什么GUI智能体很重要？

你是否曾想过让AI帮你操作手机或电脑界面？比如说"点击左上角的菜单按钮"或"滑动到页面底部"，AI就能精准执行这些指令？这就是GUI智能体的工作，它们能理解屏幕内容并执行相应操作。

目前主流的训练方法是"监督微调"（SFT），即收集大量人工标注数据来训练模型。这种方法虽然有效，但存在两个明显缺点：

1. 1. 需要**大量标注数据**（通常需要数万甚至数十万条）
2. 2. 在**未见过的场景**（如从手机到电脑界面）表现较差

## 02 革命性突破：强化学习驱动的GUI智能体

vivo AI实验室与香港中文大学的研究团队受到DeepSeek-R1的启发，首次将基于规则的强化学习（RL）应用到了GUI智能体领域。他们提出的UI-R1模型采用了三个关键创新：

### 1. 独特的奖励函数设计

研究团队设计了专门针对GUI任务的奖励函数：

```
R_A = R_T + R_C + R_F
```

这个公式看似简单，却非常巧妙：

- • R_T：行为类型奖励（点击、滑动、返回等）
- • R_C：坐标准确度奖励（点击位置是否准确）
- • R_F：格式奖励（输出的格式是否正确）

![UI-R1训练框架](https://mmbiz.qpic.cn/sz_mmbiz_png/EiaBZb67CwgnOZvV3eqicib1eCtq1ZU3kvMPyr9H7q5gshbDlEV10tSUluYyocomY4YTAELIT5ay629quoW3ic5Osg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)UI-R1训练框架

### 2. 精心筛选的高质量数据

与其使用大量普通数据，团队采用了"质量优先"的策略，从三个维度精选训练数据：

- • **质量**：选择标注准确、对齐良好的样本
- • **难度**：专注于基础模型难以解决的"困难"样本
- • **多样性**：确保涵盖各种行为类型和元素类型

最终只使用了**136个**高质量样本！这比传统方法少了几百甚至上千倍！

### 3. 群体相对策略优化算法

UI-R1采用了一种名为GRPO（Group Relative Policy Optimization）的算法。这种算法不需要额外的评论家模型，而是通过比较同一问题的多个不同回答来学习什么是"好"的回答。

## 03 令人瞠目的实验结果

### 域内性能大幅提升

在AndroidControl基准测试上，UI-R1-3B与基础模型Qwen2.5-VL-3B相比：

- • 行为类型准确率提高了**15%**
- • 定位准确率提高了**10.3%**

### 域外泛化能力惊人

最令人震惊的是，UI-R1在从未见过的桌面和网页界面上表现同样出色：

- • 在ScreenSpot测试中，UI-R1-3B的平均准确率达到**78.6%**，超越CogAgent-18B等大模型
- • 在专业高分辨率环境ScreenSpot-Pro测试中，UI-R1-3B达到**17.8%**的平均准确率，与使用76K数据训练的OS-Atlas-7B（18.9%）性能相当

![ScreenSpot准确度](https://mmbiz.qpic.cn/sz_mmbiz_png/EiaBZb67CwgnOZvV3eqicib1eCtq1ZU3kvMYsC8TZLCt1yf7moEp9n041rrAUn5p2hEmqpbicc3iaDTE3faaZJdmuIQ/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)ScreenSpot准确度

### 节省资源，性价比超高

研究团队仅使用8张NVIDIA 4090 GPU训练了约8小时，比传统SFT方法节省了大量计算资源。这种高效训练方式为资源受限环境下的模型优化提供了新思路。

## 04 数据科学的启示

UI-R1的成功证明了一个重要观点：**数据质量远比数据数量重要**。研究发现：

1. 1. **困难样本更有价值**：按难度选择的方法比随机选择的性能显著更好
2. 2. **数据增长收益递减**：随着训练数据量增加，性能提升趋于平缓
3. 3. **精选小数据集比大数据集更有效**：三阶段数据选择方法优于使用整个数据集

![数据规模和推理长度](https://mmbiz.qpic.cn/sz_mmbiz_png/EiaBZb67CwgnOZvV3eqicib1eCtq1ZU3kvMvO2t80S7vERViatrwOdj2BiaW1wTRlj153Qrg55XXCibw0q5vvbSxboibw/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)数据规模和推理长度

## 05 这对普通用户意味着什么？

UI-R1的突破将加速更智能、更自然的人机交互界面的到来：

1. 1. **更强大的手机助手**：未来你的手机助手可以真正"看懂"屏幕，帮你完成各种操作
2. 2. **跨平台适应能力**：同一AI助手可以同时帮你操作手机、电脑和网页
3. 3. **降低AI训练门槛**：小团队和研究者也能用有限资源训练出高性能模型
4. 4. **为老年人和障碍人士赋能**：使数字设备更容易使用，提高科技包容性